"""ToolCallAgentç±»"""
import asyncio
import json
from typing import List, Dict, Any, Optional, Union
from .react import ReActAgent
# å¤„ç†ç›¸å¯¹å¯¼å…¥é—®é¢˜
try:
    from ..tools.tool_manager import ToolManager
    from ..tools.base import BaseTool
    from ..schema import AgentState, Memory, Message
    from ..config.config import Config
    from ..models.llm import LLM
except (ImportError, ValueError):
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç»å¯¹å¯¼å…¥
    import sys
    from pathlib import Path
    current_file = Path(__file__).resolve()
    project_root = current_file.parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    from tools.tool_manager import ToolManager
    from tools.base import BaseTool
    from schema import AgentState, Memory, Message
    from config.config import Config
    from models.llm import LLM


class ToolCallAgent(ReActAgent):
    """ToolCallAgentï¼Œç»§æ‰¿ReActAgentï¼Œæ·»åŠ å¯ç”¨å·¥å…·é›†åˆï¼Œå®ç°thinkå’Œactæ–¹æ³•"""
    
    def __init__(
        self,
        name: str = "toolcall_agent",
        description: Optional[str] = None,
        system_prompt: Optional[str] = None,
        next_step_prompt: Optional[str] = None,
        config: Optional[Config] = None,
        memory: Optional[Memory] = None,
        state: AgentState = AgentState.IDLE,
        max_steps: int = 10,
        available_tools: Optional[List[BaseTool]] = None,
        tool_manager: Optional[ToolManager] = None,
        max_observe: Optional[Union[int, bool]] = None
    ):
        """
        åˆå§‹åŒ–ToolCallAgent
        
        Args:
            name: Agentåç§°
            description: Agentæè¿°
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            next_step_prompt: ä¸‹ä¸€æ­¥æç¤ºè¯ï¼ˆä¼šåœ¨think()ä¸­ä½¿ç”¨ï¼‰
            config: ç³»ç»Ÿé…ç½®
            memory: è®°å¿†å­˜å‚¨
            state: AgentçŠ¶æ€
            max_steps: æœ€å¤§æ‰§è¡Œæ­¥æ•°
            available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            max_observe: é™åˆ¶è§‚å¯Ÿç»“æœçš„æœ€å¤§é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
        """
        super().__init__(
            name=name,
            description=description or "An agent that can execute tool calls",
            system_prompt=system_prompt,
            next_step_prompt=next_step_prompt,
            config=config,
            memory=memory,
            state=state,
            max_steps=max_steps
        )
        
        # åˆå§‹åŒ–å·¥å…·ç®¡ç†å™¨
        self.tool_manager = tool_manager or ToolManager(self.config)
        
        # æ³¨å†Œå¯ç”¨å·¥å…·
        if available_tools:
            for tool in available_tools:
                self.tool_manager.register_tool(tool)
        
        # ç»“æœé™åˆ¶é…ç½®
        self.max_observe = max_observe
        
        # åˆå§‹åŒ–LLMï¼ˆç”¨äºNative Function Callingï¼‰
        self.llm = LLM(self.config)
        
        # è·å–å·¥å…·æ˜ å°„å­—å…¸ï¼ˆå·¥å…·åç§° -> æ‰§è¡Œå‡½æ•°ï¼‰
        self.available_functions = self.tool_manager.get_available_functions()
        
        # å½“å‰å·¥å…·è°ƒç”¨ï¼ˆä»LLMå“åº”ä¸­è·å–ï¼‰
        self.current_tool_calls: List[Dict[str, Any]] = []
    
    async def think(self) -> bool:
        """
        æ€è€ƒé˜¶æ®µï¼šä½¿ç”¨Native Function Callingï¼ˆLLMåŸç”Ÿå·¥å…·è°ƒç”¨ï¼‰
        
        Returns:
            æ˜¯å¦éœ€è¦æ‰§è¡Œè¡ŒåŠ¨
        """
        # æ›´æ–°çŠ¶æ€ï¼šæ€è€ƒé˜¶æ®µ
        self.update_status(
            f"ğŸ’­ Step {self.current_step}: æ€è€ƒä¸­...",
            "æ­£åœ¨åˆ†æé—®é¢˜ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨...",
            "running"
        )
        
        # å¦‚æœè®¾ç½®äº†next_step_promptï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
        if self.next_step_prompt:
            user_msg = Message.user_message(self.next_step_prompt)
            self.memory.add_message(user_msg)
        
        # è·å–æœ€è¿‘çš„å¯¹è¯ä¸Šä¸‹æ–‡
        recent_messages = self.memory.get_recent_messages(10)  # å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œé¿å…æˆªæ–­å·¥å…·è°ƒç”¨å¯¹
        
        # è½¬æ¢æ¶ˆæ¯ä¸ºå­—å…¸æ ¼å¼
        messages_dict = []
        for msg in recent_messages:
            if isinstance(msg, Message):
                messages_dict.append(msg.to_dict())
            elif isinstance(msg, dict):
                messages_dict.append(msg)
        
        # ä¿®å¤DashScope/OpenAI APIé™åˆ¶ï¼štoolæ¶ˆæ¯å¿…é¡»è·Ÿåœ¨tool_callsæ¶ˆæ¯ä¹‹å
        # å¦‚æœç¬¬ä¸€æ¡æ¶ˆæ¯æ˜¯toolç±»å‹ï¼Œè¯´æ˜å‰é¢çš„assistantæ¶ˆæ¯è¢«æˆªæ–­äº†ï¼Œéœ€è¦ä¸¢å¼ƒè¿™æ¡toolæ¶ˆæ¯
        while messages_dict and messages_dict[0].get("role") == "tool":
            print(f"Warning: Dropping orphaned tool message at start of context")
            messages_dict.pop(0)
        
        # è·å–æ‰€æœ‰å·¥å…·çš„JSON Schema
        tools_schema = self.tool_manager.get_tools_schema()
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = self.system_prompt or "You are a helpful assistant with access to various tools."
        
        # è°ƒç”¨LLMçš„chat_with_toolsæ–¹æ³•ï¼ˆNative Function Callingï¼‰
        try:
            response = self.llm.chat_with_tools(
                messages=messages_dict,
                tools=tools_schema,
                tool_choice="auto",  # è®©æ¨¡å‹è‡ªå·±å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·
                system_prompt=system_prompt,
                temperature=0.7,
                max_tokens=self.config.llm_max_tokens
            )
        except Exception as e:
            print(f"Error in LLM tool calling: {e}")
            self.update_memory("assistant", f"Error: {str(e)}")
            return False
        
        # æå–å›å¤å†…å®¹å’Œå·¥å…·è°ƒç”¨
        content = response.get("content", "")
        tool_calls = response.get("tool_calls", [])
        
        # è®°å½•LLMçš„æ€è€ƒå†…å®¹
        if content:
            print(f"âœ¨ {self.name}'s thoughts: {content}")
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        self.current_tool_calls = []
        if tool_calls:
            print(f"ğŸ› ï¸ {self.name} selected {len(tool_calls)} tools to use")
            tool_names = []
            for tool_call in tool_calls:
                tool_name = tool_call.get("function", {}).get("name", "")
                tool_names.append(tool_name)
                print(f"ğŸ§° Tool: {tool_name}, Arguments: {tool_call.get('function', {}).get('arguments', '')}")
                self.current_tool_calls.append(tool_call)
            
            # æ›´æ–°çŠ¶æ€ï¼šå‡†å¤‡æ‰§è¡Œå·¥å…·
            self.update_status(
                f"ğŸ› ï¸ Step {self.current_step}: å‡†å¤‡æ‰§è¡Œå·¥å…·",
                f"å‡†å¤‡è°ƒç”¨å·¥å…·: {', '.join(tool_names)}",
                "running"
            )
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå¯èƒ½æ˜¯ç”Ÿæˆæœ€ç»ˆå›ç­”
            if content and len(content) > 50:
                self.update_status(
                    f"ğŸ“ Step {self.current_step}: ç”Ÿæˆæœ€ç»ˆå›ç­”",
                    "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå›ç­”...",
                    "running"
                )
        
        # åˆ›å»ºassistantæ¶ˆæ¯ï¼ˆåŒ…å«å†…å®¹å’Œå·¥å…·è°ƒç”¨ï¼‰
        if tool_calls:
            # æœ‰å·¥å…·è°ƒç”¨
            assistant_msg = Message.from_tool_calls(
                content=content,
                tool_calls=self.current_tool_calls
            ) if hasattr(Message, 'from_tool_calls') else Message.assistant_message(
                content=content,
                tool_calls=self.current_tool_calls
            )
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œåªæœ‰æ–‡æœ¬å›å¤
            assistant_msg = Message.assistant_message(content=content)
        
        self.memory.add_message(assistant_msg)
        
        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›Trueè¡¨ç¤ºéœ€è¦æ‰§è¡Œè¡ŒåŠ¨
        if self.current_tool_calls:
            return True
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·æ‰§è¡Œç»“æœ
        has_tool_results = any(
            msg.role == "tool" for msg in self.memory.get_recent_messages(10)
        )
        
        # å¦‚æœå·²ç»æœ‰å·¥å…·æ‰§è¡Œç»“æœï¼Œéœ€è¦æ£€æŸ¥æ˜¯å¦å·²ç»ç”Ÿæˆäº†æœ€ç»ˆå›ç­”
        if has_tool_results:
            # æ£€æŸ¥æœ€åä¸€æ¡assistantæ¶ˆæ¯æ˜¯å¦åœ¨å·¥å…·ç»“æœä¹‹åï¼ˆè¯´æ˜å·²ç»ç”Ÿæˆäº†æœ€ç»ˆå›ç­”ï¼‰
            recent_msgs = self.memory.get_recent_messages(20)
            last_tool_index = -1
            last_assistant_index = -1
            
            for i, msg in enumerate(recent_msgs):
                if msg.role == "tool":
                    last_tool_index = i
                elif msg.role == "assistant" and msg.content:
                    last_assistant_index = i
            
            # å¦‚æœæœ€åä¸€æ¡assistantæ¶ˆæ¯åœ¨å·¥å…·ç»“æœä¹‹åï¼Œè¯´æ˜å·²ç»ç”Ÿæˆäº†æœ€ç»ˆå›ç­”
            if last_assistant_index > last_tool_index:
                # æ£€æŸ¥è¿™ä¸ªå›ç­”æ˜¯å¦è¶³å¤Ÿå®Œæ•´ï¼ˆä¸æ˜¯ç©ºçš„æˆ–åªæ˜¯æ€è€ƒå†…å®¹ï¼‰
                last_assistant_msg = recent_msgs[last_assistant_index]
                if last_assistant_msg.content and len(last_assistant_msg.content) > 50:
                    # å·²ç»æœ‰å®Œæ•´çš„æœ€ç»ˆå›ç­”ï¼Œå¯ä»¥ç»“æŸ
                    self.state = AgentState.FINISHED
                    return False
            
            # å¦‚æœæœ‰å·¥å…·ç»“æœä½†è¿˜æ²¡æœ‰åŸºäºå·¥å…·ç»“æœçš„æœ€ç»ˆå›ç­”
            # å½“å‰LLMè°ƒç”¨åº”è¯¥ä¼šç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆå› ä¸ºmessagesä¸­åŒ…å«äº†toolç»“æœï¼‰
            # å¦‚æœcontentä¸ä¸ºç©ºï¼Œè¯´æ˜LLMå·²ç»ç”Ÿæˆäº†å›ç­”
            if content and len(content) > 50:
                # LLMå·²ç»åŸºäºå·¥å…·ç»“æœç”Ÿæˆäº†æœ€ç»ˆå›ç­”
                self.state = AgentState.FINISHED
                return False
            # å¦‚æœcontentä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯LLMè¿˜åœ¨æ€è€ƒï¼Œç»§ç»­ç­‰å¾…ä¸‹ä¸€è½®
        
        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ä½†æœ‰å†…å®¹ï¼Œæ£€æŸ¥æ˜¯å¦å¯ä»¥ç»“æŸ
        if content and not has_tool_results:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å®Œæ•´çš„å›ç­”
            if len(content) > 50:  # ç®€å•åˆ¤æ–­ï¼šå†…å®¹è¾ƒé•¿å¯èƒ½æ˜¯å®Œæ•´å›ç­”
                self.state = AgentState.FINISHED
                return False
        
        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ä¹Ÿæ²¡æœ‰å†…å®¹ï¼Œç»§ç»­æ€è€ƒ
        return False
    
    async def act(self) -> str:
        """
        è¡ŒåŠ¨é˜¶æ®µï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨
        
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        if not self.current_tool_calls:
            return "No tools to execute"
        
        results = []
        for idx, tool_call in enumerate(self.current_tool_calls):
            tool_name = tool_call.get("function", {}).get("name", "")
            # æ›´æ–°çŠ¶æ€ï¼šæ‰§è¡Œå·¥å…·
            self.update_status(
                f"âš¡ Step {self.current_step}: æ‰§è¡Œå·¥å…· ({idx+1}/{len(self.current_tool_calls)})",
                f"æ­£åœ¨æ‰§è¡Œå·¥å…·: {tool_name}...",
                "running"
            )
            
            result = await self.execute_tool(tool_call)
            
            # é™åˆ¶è§‚å¯Ÿç»“æœé•¿åº¦
            if self.max_observe and isinstance(self.max_observe, int):
                result = result[:self.max_observe]
            
            print(f"ğŸ¯ Tool '{tool_call['function']['name']}' completed: {result[:100] if len(result) > 100 else result}...")
            
            # æ·»åŠ å·¥å…·å“åº”åˆ°è®°å¿†
            tool_msg = Message.tool_message(
                content=result,
                tool_call_id=tool_call.get("id", ""),
                name=tool_call["function"]["name"]
            )
            self.memory.add_message(tool_msg)
            results.append(result)
        
        # æ¸…ç©ºå·¥å…·è°ƒç”¨
        self.current_tool_calls = []
        
        return "\n\n".join(results)
    
    async def execute_tool(self, tool_call: Dict[str, Any]) -> str:
        """
        æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨ï¼ˆä½¿ç”¨æ˜ å°„å­—å…¸ï¼‰
        
        Args:
            tool_call: å·¥å…·è°ƒç”¨å­—å…¸ï¼ˆæ¥è‡ªLLMçš„tool_callsï¼‰
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        if not tool_call or not tool_call.get("function") or not tool_call["function"].get("name"):
            return "Error: Invalid command format"
        
        name = tool_call["function"]["name"]
        
        # ä»æ˜ å°„å­—å…¸ä¸­è·å–å·¥å…·çš„æ‰§è¡Œå‡½æ•°
        tool_function = self.available_functions.get(name)
        
        if not tool_function:
            return f"Error: Unknown tool '{name}'"
        
        try:
            # è§£æå‚æ•°ï¼ˆLLMè¿”å›çš„argumentsæ˜¯JSONå­—ç¬¦ä¸²ï¼‰
            args_str = tool_call["function"].get("arguments", "{}")
            args_dict = json.loads(args_str) if isinstance(args_str, str) else args_str
            
            print(f"ğŸ”§ Activating tool: '{name}' with arguments: {args_dict}")
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context = {
                "messages": [msg.to_dict() for msg in self.memory.get_recent_messages(10)],
                "max_results": args_dict.get("max_results", 5)
            }
            
            # ä»å‚æ•°ä¸­æå–ç”¨æˆ·è¾“å…¥ï¼ˆå…¼å®¹å¤šç§å‚æ•°åï¼‰
            # æ ¹æ®å·¥å…·schemaçš„ä¸åŒï¼Œå‚æ•°åå¯èƒ½ä¸åŒ
            # å¯¹äºdocument_toolï¼Œéœ€è¦ä¼ é€’å®Œæ•´çš„args_dictä½œä¸ºcontext
            if name == "generate_legal_document":
                # æ–‡æ¡£ç”Ÿæˆå·¥å…·éœ€è¦title, content, file_formatå‚æ•°
                context.update(args_dict)  # å°†å‚æ•°æ·»åŠ åˆ°contextä¸­
                tool_input = json.dumps(args_dict, ensure_ascii=False)  # å°†å‚æ•°è½¬ä¸ºJSONå­—ç¬¦ä¸²
            else:
                tool_input = (
                    args_dict.get("query") or 
                    args_dict.get("url") or 
                    args_dict.get("city") or 
                    args_dict.get("code") or
                    args_dict.get("expression") or
                    args_dict.get("file_path") or
                    args_dict.get("input") or 
                    args_dict.get("user_input") or
                    str(args_dict)  # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°†æ•´ä¸ªå­—å…¸è½¬ä¸ºå­—ç¬¦ä¸²
                )
            
            # æ‰§è¡Œå·¥å…·ï¼ˆä½¿ç”¨æ˜ å°„å­—å…¸ä¸­çš„å‡½æ•°ï¼‰
            # æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥å·¥å…·
            if asyncio.iscoroutinefunction(tool_function):
                result = await tool_function(user_input=tool_input, context=context)
            else:
                result = tool_function(user_input=tool_input, context=context)
            
            # æ ¼å¼åŒ–ç»“æœ
            observation = (
                f"Observed output of cmd `{name}` executed:\n{str(result)}"
                if result
                else f"Cmd `{name}` completed with no output"
            )
            
            # é™åˆ¶è§‚å¯Ÿç»“æœé•¿åº¦
            if self.max_observe and isinstance(observation, str):
                if isinstance(self.max_observe, bool) and self.max_observe:
                    # å¦‚æœmax_observeæ˜¯Trueï¼Œä½¿ç”¨é»˜è®¤é™åˆ¶
                    max_len = 2000
                else:
                    max_len = self.max_observe
                
                if len(observation) > max_len:
                    observation = observation[:max_len] + "\n\n[Output truncated...]"
            
            return observation
            
        except json.JSONDecodeError:
            error_msg = f"Error parsing arguments for {name}: Invalid JSON format"
            print(f"ğŸ“ Error: {error_msg}, arguments: {tool_call['function'].get('arguments')}")
            return f"Error: {error_msg}"
        except Exception as e:
            error_msg = f"âš ï¸ Tool '{name}' encountered a problem: {str(e)}"
            print(f"ğŸš¨ {error_msg}")
            import traceback
            traceback.print_exc()
            return f"Error: {error_msg}"
    
    async def cleanup(self):
        """æ¸…ç†Agentä½¿ç”¨çš„èµ„æºï¼ˆå‚è€ƒæ ‡å‡†å®ç°ï¼‰"""
        print(f"ğŸ§¹ Cleaning up resources for agent '{self.name}'...")
        for tool_name, tool_instance in self.tool_manager.tools.items():
            if hasattr(tool_instance, "cleanup") and asyncio.iscoroutinefunction(
                tool_instance.cleanup
            ):
                try:
                    print(f"ğŸ§¼ Cleaning up tool: {tool_name}")
                    await tool_instance.cleanup()
                except Exception as e:
                    print(f"ğŸš¨ Error cleaning up tool '{tool_name}': {e}")
        print(f"âœ¨ Cleanup complete for agent '{self.name}'.")
    
    async def run(self, request: Optional[str] = None, status_callback=None, context: str = "") -> str:
        """
        è¿è¡ŒAgentï¼ˆä¸åœ¨è¿™é‡Œæ¸…ç†ï¼Œç”±execute_taskå®Œæˆåæ¸…ç†ï¼‰
        
        Args:
            request: å¯é€‰çš„åˆå§‹ç”¨æˆ·è¯·æ±‚
            status_callback: å¯é€‰çš„çŠ¶æ€å›è°ƒå‡½æ•°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œç”¨äºæ— çŠ¶æ€æ‰§è¡Œï¼‰
            
        Returns:
            æ‰§è¡Œç»“æœæ‘˜è¦
        """
        # ä¸åœ¨runæ–¹æ³•ä¸­æ¸…ç†ï¼Œå› ä¸ºexecute_taskè¿˜éœ€è¦è¿›è¡ŒCriticè¯„ä¼°
        # æ¸…ç†å°†åœ¨execute_taskå®Œæˆåè¿›è¡Œ
        return await super().run(request, status_callback, context)
    
    def _generate_tool_arguments(
        self,
        tool_name: str,
        user_query: str,
        recent_messages: List[Message]
    ) -> str:
        """
        ä½¿ç”¨LLMç”Ÿæˆå·¥å…·è°ƒç”¨çš„å‚æ•°
        
        Args:
            tool_name: å·¥å…·åç§°
            user_query: ç”¨æˆ·æŸ¥è¯¢
            recent_messages: æœ€è¿‘æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            å·¥å…·å‚æ•°çš„JSONå­—ç¬¦ä¸²
        """
        # è·å–å·¥å…·æè¿°
        tool = self.tool_manager.get_tool(tool_name)
        if not tool:
            return "{}"
        
        tool_description = tool.get_description()
        
        # æ„å»ºprompt
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªå·¥å…·å‚æ•°ç”ŸæˆåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·æŸ¥è¯¢å’Œå·¥å…·æè¿°ï¼Œç”Ÿæˆå·¥å…·è°ƒç”¨æ‰€éœ€çš„å‚æ•°ã€‚
è¦æ±‚ï¼š
1. å‚æ•°å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼
2. åªåŒ…å«å·¥å…·éœ€è¦çš„å‚æ•°
3. ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–ç›¸å…³ä¿¡æ¯ä½œä¸ºå‚æ•°å€¼"""
        
        user_prompt = f"""å·¥å…·åç§°ï¼š{tool_name}
å·¥å…·æè¿°ï¼š{tool_description}
ç”¨æˆ·æŸ¥è¯¢ï¼š{user_query}

è¯·ç”Ÿæˆå·¥å…·è°ƒç”¨æ‰€éœ€çš„å‚æ•°ï¼ˆJSONæ ¼å¼ï¼‰ï¼š"""
        
        try:
            # ä½¿ç”¨LLMç”Ÿæˆå‚æ•°
            response = self.llm.chat(
                messages=[{"role": "user", "content": user_prompt}],
                system_prompt=system_prompt,
                temperature=0.1,  # ä½¿ç”¨ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ
                max_tokens=200
            )
            
            # å°è¯•è§£æJSON
            import json
            try:
                # å°è¯•æå–JSON
                response = response.strip()
                if response.startswith("```"):
                    # ç§»é™¤ä»£ç å—æ ‡è®°
                    response = response.split("```")[1]
                    if response.startswith("json"):
                        response = response[4:]
                response = response.strip()
                
                # è§£æJSON
                args = json.loads(response)
                return json.dumps(args, ensure_ascii=False)
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›ç©ºå­—å…¸
                return "{}"
        
        except Exception as e:
            print(f"Warning: Failed to generate tool arguments: {e}")
            return "{}"
    
    def _heuristic_tool_selection(
        self,
        user_query: str,
        messages_dict: List[Dict[str, Any]]
    ) -> List[str]:
        """
        åŸºäºå…³é”®è¯çš„å¯å‘å¼å·¥å…·é€‰æ‹©ï¼ˆå½“embeddingé€‰æ‹©å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            messages_dict: æ¶ˆæ¯å­—å…¸åˆ—è¡¨
            
        Returns:
            é€‰ä¸­çš„å·¥å…·åç§°åˆ—è¡¨
        """
        query_lower = user_query.lower()
        selected = []
        
        # æœç´¢ç›¸å…³å…³é”®è¯
        search_keywords = ["ä»€ä¹ˆ", "å¦‚ä½•", "æ€æ ·", "æŸ¥è¯¢", "æœç´¢", "æŸ¥æ‰¾", "æ£€ç´¢", "äº†è§£", "ä»‹ç»", "å®šä¹‰", "æœ€æ–°", "åˆ†æ"]
        if any(keyword in query_lower for keyword in search_keywords):
            if "web_search" in self.tool_manager.tools:
                selected.append("web_search")
        
        # æ³¨æ„ï¼šå·²ç§»é™¤url_readerå·¥å…·ï¼ŒåšæŸ¥æœç´¢è¿”å›çš„æ‘˜è¦å·²ç»è¶³å¤Ÿè¯¦ç»†
        
        # è®¡ç®—ç›¸å…³å…³é”®è¯
        calc_keywords = ["è®¡ç®—", "å¤šå°‘", "èµ”å¿", "è´¹ç”¨", "é‡‘é¢", "å…¬å¼", "ç­‰äº"]
        if any(keyword in query_lower for keyword in calc_keywords):
            if "python_executor" in self.tool_manager.tools:
                selected.append("python_executor")
            elif "calculator" in self.tool_manager.tools:
                selected.append("calculator")
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰é€‰æ‹©åˆ°å·¥å…·ï¼Œé»˜è®¤ä½¿ç”¨web_searchï¼ˆå¯¹äºQAç±»ä»»åŠ¡ï¼‰
        if not selected and "web_search" in self.tool_manager.tools:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç³»ç»Ÿæç¤ºè¯æåˆ°éœ€è¦æœç´¢
            for msg in messages_dict:
                if msg.get("role") == "system" and "æœç´¢" in msg.get("content", ""):
                    selected.append("web_search")
                    break
        
        return selected
    
    def _generate_final_answer(self, recent_messages: List[Message]) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼ˆå½“å·¥å…·æ‰§è¡Œå®Œæˆåï¼‰
        
        Args:
            recent_messages: æœ€è¿‘çš„æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            æœ€ç»ˆç­”æ¡ˆæ–‡æœ¬
        """
        # æ„å»ºprompt
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œå·¥å…·æ‰§è¡Œç»“æœï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€å‡†ç¡®çš„ç­”æ¡ˆã€‚
è¦æ±‚ï¼š
1. ç­”æ¡ˆè¦å®Œæ•´ã€å‡†ç¡®
2. å¦‚æœå·¥å…·æ‰§è¡Œç»“æœä¸­æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¦å……åˆ†åˆ©ç”¨
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œå¯ä»¥è¯´æ˜éœ€è¦æ›´å¤šä¿¡æ¯"""
        
        # æ„å»ºæ¶ˆæ¯å†å²
        messages_dict = []
        for msg in recent_messages[-10:]:  # åªä½¿ç”¨æœ€è¿‘10æ¡æ¶ˆæ¯
            if isinstance(msg, Message):
                messages_dict.append(msg.to_dict())
            elif isinstance(msg, dict):
                messages_dict.append(msg)
        
        try:
            # ä½¿ç”¨LLMç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            response = self.llm.chat(
                messages=messages_dict,
                system_prompt=system_prompt,
                temperature=0.7,
                max_tokens=500
            )
            return response.strip() if response else ""
        except Exception as e:
            print(f"Warning: Failed to generate final answer: {e}")
            return ""

